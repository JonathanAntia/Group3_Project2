{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def SQL_Pull(budget):\n",
    "    engine= create_engine(\"postgres://wtzcxlhtevtgnn:a611ddfea80402e93d32df58dad93c3dfe320544d635b77e14e9bb8936eeca9e@ec2-52-86-116-94.compute-1.amazonaws.com:5432/d5hl5ab4698nnc\")\n",
    "    Base= automap_base()\n",
    "    Base.prepare(engine, reflect=True)\n",
    "    \n",
    "    appraisal=Base.classes.appraisal\n",
    "    properties=Base.classes.properties\n",
    "    crime=Base.classes.crime\n",
    "    zip_code=Base.classes.zip_code\n",
    "    flood_zone=Base.classes.flood_zone\n",
    "    neighborhoods=Base.classes.neighborhoods\n",
    "    # property_school=Base.classes.property_school\n",
    "    school_district=Base.classes.school_district\n",
    "    school=Base.classes.school\n",
    "    session=Session(bind=engine)\n",
    "    \n",
    "    sel=[appraisal.id,appraisal.account,appraisal.land_value,appraisal.total_appraised_value,appraisal.total_market_value,appraisal.tax_year,\\\n",
    "      properties.latitude, properties.longitude, properties.Zip_code, properties.neighborhood_code,properties.acreage,\\\n",
    "      properties.new_owner_date, properties.sq_ft, properties.flood_description,\\\n",
    "      neighborhoods.neighborhood]\n",
    "\n",
    "    appraisal_df=session.query(*sel).\\\n",
    "            select_from(join(join(appraisal, properties, appraisal.account==properties.account),neighborhoods,\\\n",
    "                           properties.neighborhood_code== neighborhoods.neighborhood_code)).\\\n",
    "            filter(appraisal.total_appraised_value<=budget).\\\n",
    "            filter(properties.sq_ft<9000).\\\n",
    "            all()\n",
    "\n",
    "    appraisal_df=pd.DataFrame(appraisal_df)\n",
    "    \n",
    "     # Calculate % of change of value between 2018 and 2019\n",
    "    appraisal_2018=appraisal_df.loc[appraisal_df.tax_year==2018,:]\n",
    "    appraisal_2019=appraisal_df.loc[appraisal_df.tax_year==2019,:]\n",
    "    appraisal_df=pd.merge(appraisal_2019,appraisal_2018,on='account', suffixes=('_2019','_2018'))\n",
    "    appraisal_df['pct_value_change']=(appraisal_df['total_appraised_value_2019']-appraisal_df['total_appraised_value_2018'])\\\n",
    "                                  /appraisal_df['total_appraised_value_2018']*100\n",
    "    results_df=appraisal_df[['id_2019','account','total_appraised_value_2019', 'pct_value_change','latitude_2019',\\\n",
    "                            'longitude_2019','acreage_2019','Zip_code_2019','neighborhood_code_2019','sq_ft_2019','neighborhood_2019', 'new_owner_date_2019',\\\n",
    "                             'flood_description_2019']]\n",
    "    results_df=results_df.rename(columns={'id_2019':'id', 'latitude_2019':'latitude','longitude_2019':'longitude',\\\n",
    "                                     'Zip_code_2019':'zip_code','neighborhood_code_2019':'neighborhood_code',\\\n",
    "                                      'sq_ft_2019':'sq_ft','neighborhood_2019':'neighborhood','acreage_2019':'acreage',\\\n",
    "                                       'flood_description_2019':'flood_description','new_owner_date_2019':'new_owner_date'})\n",
    "    sel=[crime.Zip_Code, func.count(crime.Offense_Count)]\n",
    "    crime_df=session.query(*sel).select_from(crime).group_by(crime.Zip_Code).all()\n",
    "    # crime_df=pd.DataFrame(crime_df)\n",
    "    crime_df=pd.DataFrame(crime_df,columns=['zip_code','Offense_Count'])\n",
    "    crime_df.head()\n",
    "    results_df=pd.merge(results_df,crime_df,on=\"zip_code\")\n",
    "    \n",
    "    #Read property_school table and merge to results\n",
    "    property_school_df=pd.read_sql_table('property_school',engine)\n",
    "    results_df=pd.merge(results_df,property_school_df,on=\"account\")\n",
    "\n",
    "    #Read school table and merge to results\n",
    "    school_df=pd.read_sql_table('school',engine)\n",
    "    results_df=pd.merge(results_df,school_df,on=['school_id','school_type'])\n",
    "\n",
    "    #Add flood ranking#3- High Risk\n",
    "    #2 - Medium Risk\n",
    "    #1- Low Risk\n",
    "    results_df['flood_risk']=np.where(results_df['flood_description']=='AREA OF MINIMAL FLOOD HAZARD',1,3)\n",
    "    results_df.loc[(results_df['flood_description']=='0.2 PCT ANNUAL CHANCE FLOOD HAZARD'),'flood_risk']=2\n",
    "    results_df.loc[(results_df['flood_description']=='FLOODWAY'),'flood_risk']=3\n",
    "    del results_df['name']\n",
    "    del results_df['address']\n",
    "    del results_df['city']\n",
    "    del results_df['zip_code_y']\n",
    "    del results_df['district_id']\n",
    "    del results_df['latitude_y']\n",
    "    del results_df['longitude_y']\n",
    "    del results_df['flood_description']\n",
    "    results_df=results_df.rename(columns={'latitude_x':'latitude', 'longitude_x':'longitude', 'zip_code_x':'zip_code'})\n",
    "    \n",
    "    #Count the house sale per neighborhood in 2019 and merge results\n",
    "    results_df=results_df.loc[results_df['account']!=530420000012,:]\n",
    "    results_df['new_owner_date']=pd.to_datetime(results_df['new_owner_date'])\n",
    "    results_df['sales2019']=np.where(results_df['new_owner_date']>'2018-12-31',1,0)\n",
    "    sales=results_df.groupby('neighborhood_code')['sales2019'].sum()\n",
    "    sales=pd.DataFrame(sales)\n",
    "    sales=sales.rename(columns={'sales2019':'sales_neighborhood_2019'})\n",
    "    results_df=pd.merge(results_df,sales, on=\"neighborhood_code\")\n",
    "    del results_df['sales2019']\n",
    "    print('data pull complete')\n",
    "    results_df.to_csv('results.csv')\n",
    "    return (results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaryOfUserInput={\n",
    "    \"budget\":1000000,\n",
    "    \"sales\":5,\n",
    "    \"crime\":5,\n",
    "    \"schools\":5,\n",
    "    \"acreage\":5,\n",
    "    \"sqft\":5,\n",
    "    \"flood\":5,\n",
    "    \"change\":5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data pull complete\n"
     ]
    }
   ],
   "source": [
    "df=SQL_Pull(dictionaryOfUserInput[\"budget\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores (dictionaryOfUserInput):\n",
    "    w_budget = dictionaryOfUserInput[\"budget\"]\n",
    "    w_sales = dictionaryOfUserInput[\"sales\"]\n",
    "    w_crime = dictionaryOfUserInput[\"crime\"]\n",
    "    w_schools = dictionaryOfUserInput[\"schools\"]\n",
    "    w_acreage = dictionaryOfUserInput[\"acreage\"]\n",
    "    w_SQ_FT = dictionaryOfUserInput[\"sqft\"]\n",
    "    w_flood = dictionaryOfUserInput[\"flood\"]\n",
    "    w_change = dictionaryOfUserInput[\"change\"]\n",
    "\n",
    "    # call SQL_Pull function to query the database and create a dataframe\n",
    "    df = SQL_Pull(w_budget)\n",
    "    \n",
    "    # Normalize data for each parameter\n",
    "    max=df['sales_neighborhood_2019'].max()\n",
    "    min=df['sales_neighborhood_2019'].min()\n",
    "    df[\"Sales Index\"]=(df['sales_neighborhood_2019']-min)/(max-min)*100\n",
    "    \n",
    "    max=df['Offense_Count'].max()\n",
    "    min=df['Offense_Count'].min()\n",
    "    df[\"Crime Index\"]=(df['Offense_Count']-min)/(max-min)*100\n",
    "\n",
    "    max=df['school_rating'].max()\n",
    "    min=df['school_rating'].min()\n",
    "    df[\"School Rating Index\"]=(df['school_rating']-min)/(max-min)*100\n",
    "\n",
    "    max=df['acreage'].max()\n",
    "    min=df['acreage'].min()\n",
    "    df[\"Acreage Index\"]=(df['acreage']-min)/(max-min)*100\n",
    "\n",
    "    max=df['sq_ft'].max()\n",
    "    min=df['sq_ft'].min()\n",
    "    df[\"SQ_FT Index\"]=(df['sq_ft']-min)/(max-min)*100\n",
    "\n",
    "    max=df['flood_risk'].max()\n",
    "    min=df['flood_risk'].min()\n",
    "    df[\"Flood Risk Index\"]=(df['flood_risk']-min)/(max-min)*100\n",
    "\n",
    "    max=df['pct_value_change'].max()\n",
    "    df['Valuation Index']=df['pct_value_change']/max*100\n",
    "\n",
    "    # Calculate scores for each address.\n",
    "    total_weights=w_sales+w_crime+w_schools+w_acreage+w_SQ_FT+w_flood+w_change\n",
    "    \n",
    "    # Add calculated scores to the dataframe\n",
    "    df[\"Sales Index_W\"]=w_sales*df['Sales Index']\n",
    "    df['Crime Index_W']= w_crime*df['Crime Index']\n",
    "    df[\"School Rating Index_W\"]=w_schools*df['School Rating Index']\n",
    "    df[\"Acreage Index_W\"]= w_acreage*df['Acreage Index']\n",
    "    df[\"SQ_FT_Index_W\"]= w_SQ_FT*df['SQ_FT Index']\n",
    "    df[\"Flood Risk Index_W\"]=w_flood*df['Flood Risk Index']\n",
    "    df['Valuation Index_W']= w_change*df['Valuation Index']\n",
    "\n",
    "    # Calculate total score per row\n",
    "    df[\"Score\"]=round((w_sales*df['Sales Index']-\n",
    "                                    w_crime*df['Crime Index']+\n",
    "                                    w_schools*df['School Rating Index']+\n",
    "                                    w_acreage*df['Acreage Index']+\n",
    "                                    w_SQ_FT*df['SQ_FT Index']-\n",
    "                                    w_flood*df['Flood Risk Index']+\n",
    "                                    w_change*df['Valuation Index'])/total_weights,2)\n",
    "\n",
    "    # look at only the parameters of interest\n",
    "    parameter_and_score = df[[\"Sales Index\",'Crime Index', 'School Rating Index',\n",
    "            'Acreage Index','SQ_FT Index', 'Flood Risk Index', 'Valuation Index','Score',\n",
    "            'total_appraised_value_2019','neighborhood']]\n",
    "\n",
    "    # group parameters by neighborhood name\n",
    "    neighborhood_group = parameter_and_score.groupby(['neighborhood']).mean()\n",
    "\n",
    "    # To get to the top list, neighnorhoods need positive valuation index and non-zero sales index\n",
    "    neighborhood_group=neighborhood_group.loc[(neighborhood_group['Valuation Index']>0)&(neighborhood_group['Sales Index']>0)&(neighborhood_group['Score']>0),:]\n",
    "\n",
    "    min=neighborhood_group['Valuation Index'].min()\n",
    "    max=neighborhood_group['Valuation Index'].max()\n",
    "    neighborhood_group['Valuation Index']=(neighborhood_group['Valuation Index']-min)/(max-min)*100\n",
    "\n",
    "    min=neighborhood_group['Score'].min()\n",
    "    max=neighborhood_group['Score'].max()\n",
    "    neighborhood_group['Score']=(neighborhood_group['Score']-min)/(max-min)*100                                                                                                                        \n",
    "\n",
    "    min=neighborhood_group['Sales Index'].min()\n",
    "    max=neighborhood_group['Sales Index'].max()\n",
    "    neighborhood_group['Sales Index']=(neighborhood_group['Sales Index']-min)/(max-min)*100 \n",
    "\n",
    "    min=neighborhood_group['Crime Index'].min()\n",
    "    max=neighborhood_group['Crime Index'].max()\n",
    "    neighborhood_group['Crime Index']=(neighborhood_group['Crime Index']-min)/(max-min)*100   \n",
    "\n",
    "    min=neighborhood_group['School Rating Index'].min()\n",
    "    max=neighborhood_group['School Rating Index'].max()\n",
    "    neighborhood_group['School Rating Index']=(neighborhood_group['School Rating Index']-min)/(max-min)*100\n",
    "\n",
    "    min=neighborhood_group['Acreage Index'].min()\n",
    "    max=neighborhood_group['Acreage Index'].max()\n",
    "    neighborhood_group['Acreage Index']=(neighborhood_group['Acreage Index']-min)/(max-min)*100 \n",
    "\n",
    "    min=neighborhood_group['SQ_FT Index'].min()\n",
    "    max=neighborhood_group['SQ_FT Index'].max()\n",
    "    neighborhood_group['SQ_FT Index']=(neighborhood_group['SQ_FT Index']-min)/(max-min)*100                                                                                                                          \n",
    "\n",
    "    min=neighborhood_group['Flood Risk Index'].min()\n",
    "    max=neighborhood_group['Flood Risk Index'].max()\n",
    "    neighborhood_group['Flood Risk Index']=(neighborhood_group['Flood Risk Index']-min)/(max-min)*100   \n",
    "\n",
    "    neighborhood_group=neighborhood_group.rename(columns={\"total_appraised_value_2019\":\"Mean Value 2019\"})                                                                                                                  \n",
    "\n",
    "    # sort scores\n",
    "    ranked_neighborhoods = neighborhood_group.sort_values('Score',ascending=False)\n",
    "    ranked_neighborhoods.to_csv('ranked_neighborhoods2.csv')\n",
    "    top5neighborhoods= ranked_neighborhoods.head()\n",
    "    return top5neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
